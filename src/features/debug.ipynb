{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import unittest\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "from rich import print\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def prepare_data(data, test_size=0.2):\n",
    "    target = \"track_popularity\"\n",
    "    X = data.drop(columns=[target])\n",
    "    y = pd.cut(data[target], bins=[-1, 20, 50, 80, 101], labels=[1, 2, 3, 4], right=False)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"data/raw/spotify_songs_train.csv\")\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = prepare_data(data)\n",
    "\n",
    "# Save the train and test data as a pickle file\n",
    "with open(\"train_test_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X_train, X_test, y_train, y_test), f)\n",
    "# ## Feature engineering\n",
    "#\n",
    "\n",
    "\n",
    "class TopArtistTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_top_artists=10):\n",
    "        self.num_top_artists = num_top_artists\n",
    "        self.top_artists = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X[\"release_date__year\"] = pd.to_datetime(\n",
    "            X[\"track_album_release_date\"], errors=\"coerce\"\n",
    "        ).dt.year\n",
    "        songs_last_decade = X[\n",
    "            X[\"release_date__year\"] >= X[\"release_date__year\"].max() - 10\n",
    "        ]\n",
    "\n",
    "        top_artists = (\n",
    "            songs_last_decade.groupby(\"track_artist\")\n",
    "            .agg({\"track_id\": \"count\"})\n",
    "            .rename(\n",
    "                columns={\n",
    "                    \"track_id\": \"number_of_tracks\",\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "        top_artists = top_artists.sort_values(\n",
    "            [\"number_of_tracks\"], ascending=[False]\n",
    "        ).head(self.num_top_artists)\n",
    "\n",
    "        self.top_artists = top_artists.index\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        is_top_artist = X[\"track_artist\"].isin(self.top_artists)\n",
    "        return is_top_artist.to_frame(name=\"is_top_artist\")\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [\"is_top_artist\"]\n",
    "\n",
    "\n",
    "# def get_num_playlists(X):\n",
    "#     num_playlist = X.groupby(\"track_id\")[\"playlist_id\"].transform(\"nunique\").values\n",
    "\n",
    "#     return np.column_stack([num_playlist])\n",
    "\n",
    "\n",
    "# def playlist_name(X, feature_names):\n",
    "#     return [\"num_playlists\"]\n",
    "\n",
    "def convert_to_datetime(data, date_column):\n",
    "    data[date_column] = pd.to_datetime(data[date_column], errors=\"coerce\")\n",
    "    return data\n",
    "\n",
    "def filter_null_dates(data, date_column):\n",
    "    not_null_mask = (data[date_column].dt.month.notnull() & data[date_column].dt.day.notnull())\n",
    "    data = data[not_null_mask]\n",
    "    return data\n",
    "\n",
    "\n",
    "def release_date(X):\n",
    "    X = pd.to_datetime(X, errors=\"coerce\")\n",
    "\n",
    "    month = X.dt.month\n",
    "    day = X.dt.day\n",
    "\n",
    "    month_season = month.map(\n",
    "        {\n",
    "            1: \"Winter\",\n",
    "            2: \"Winter\",\n",
    "            3: \"Spring\",\n",
    "            4: \"Spring\",\n",
    "            5: \"Spring\",\n",
    "            6: \"Summer\",\n",
    "            7: \"Summer\",\n",
    "            8: \"Summer\",\n",
    "            9: \"Fall\",\n",
    "            10: \"Fall\",\n",
    "            11: \"Fall\",\n",
    "            12: \"Winter\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    day_category = pd.cut(\n",
    "        day,\n",
    "        bins=[0, 10, 20, 31],\n",
    "        labels=[\"First 10\", \"Middle 10\", \"Last 10\"],\n",
    "        right=False,\n",
    "    )\n",
    "\n",
    "    return np.column_stack([month_season, day_category])\n",
    "\n",
    "\n",
    "def release_date_name(X, feature_names):\n",
    "    return [\"month_season\", \"day_category\"]\n",
    "\n",
    "\n",
    "def get_is_remix_or_collab(X):\n",
    "    is_remix = X.str.contains(\"remix\", case=False).astype(int)\n",
    "    is_collab = X.str.contains(r\"(feat|ft\\.|\\(with)\", case=False).astype(int)\n",
    "    return np.column_stack([is_remix, is_collab])\n",
    "\n",
    "\n",
    "def is_remix_or_collab_name(X, feature_names):\n",
    "    return [\"is_remix\", \"is_collab\"]\n",
    "\n",
    "\n",
    "def get_is_weekend(X):\n",
    "    X = pd.to_datetime(X, errors=\"coerce\")\n",
    "    return X.dt.dayofweek.isin([5, 6]).astype(int).values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def is_weekend_name(X, feature_names):\n",
    "    return [\"is_weekend\"]\n",
    "\n",
    "\n",
    "# num_playlist_pipeline = make_pipeline(\n",
    "#     FunctionTransformer(\n",
    "#         get_num_playlists,\n",
    "#         validate=False,\n",
    "#         feature_names_out=playlist_name,\n",
    "#     ),\n",
    "#     StandardScaler(),\n",
    "# )\n",
    "\n",
    "release_date_pipeline = make_pipeline(\n",
    "    FunctionTransformer(\n",
    "        release_date, validate=False, feature_names_out=release_date_name\n",
    "    ),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "num_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "date_transformer = make_pipeline(\n",
    "    FunctionTransformer(convert_to_datetime, validate=False, kw_args={\"date_column\": \"track_album_release_date\"}),\n",
    "    FunctionTransformer(filter_null_dates, validate=False, kw_args={\"date_column\": \"track_album_release_date\"})\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "feature_engineering = ColumnTransformer(\n",
    "    [\n",
    "        # (\n",
    "        #     \"num_playlists\",\n",
    "        #     num_playlist_pipeline,\n",
    "        #     [\"track_id\", \"playlist_id\"],\n",
    "        # ),\n",
    "        (\"date\",\n",
    "        date_transformer,\n",
    "        \"track_album_release_date\"\n",
    "        \n",
    "        ),\n",
    "\n",
    "        \n",
    "        (\n",
    "            \"release_date\",\n",
    "            release_date_pipeline,\n",
    "            \"track_album_release_date\",\n",
    "        ),\n",
    "        (\n",
    "            \"release_day\",\n",
    "            FunctionTransformer(\n",
    "                get_is_weekend, validate=False, feature_names_out=is_weekend_name\n",
    "            ),\n",
    "            \"track_album_release_date\",\n",
    "        ),\n",
    "        (\n",
    "            \"top_artist\",\n",
    "            TopArtistTransformer(num_top_artists=50),\n",
    "            [\n",
    "                \"track_artist\",\n",
    "                \"track_album_release_date\",\n",
    "                \"track_id\",\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            \"genres\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "            [\"playlist_genre\", \"playlist_subgenre\"],\n",
    "        ),\n",
    "        (\n",
    "            \"track_name\",\n",
    "            FunctionTransformer(\n",
    "                get_is_remix_or_collab,\n",
    "                validate=False,\n",
    "                feature_names_out=is_remix_or_collab_name,\n",
    "            ),\n",
    "            \"track_name\",\n",
    "        ),\n",
    "        (\n",
    "            \"numerical\",\n",
    "            num_pipeline,\n",
    "            [\n",
    "                \"danceability\",\n",
    "                \"energy\",\n",
    "                \"loudness\",\n",
    "                \"speechiness\",\n",
    "                \"acousticness\",\n",
    "                \"instrumentalness\",\n",
    "                \"liveness\",\n",
    "                \"valence\",\n",
    "                \"tempo\",\n",
    "                \"duration_ms\",\n",
    "            ],\n",
    "        ),\n",
    "        (\n",
    "            \"key\",\n",
    "            OrdinalEncoder(),\n",
    "            [\"key\"],\n",
    "        ),\n",
    "        (\"mode\", \"passthrough\", [\"mode\"]),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "\n",
    "feature_engineering.fit(X_train)\n",
    "with open(\"./src/features/feature_engineering.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_engineering, f)\n",
    "\n",
    "\n",
    "\n",
    "# ### Unit Test\n",
    "\n",
    "\n",
    "class TestTopArtistTransformer(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Sample data\n",
    "        self.data = pd.DataFrame(\n",
    "            {\n",
    "                \"track_album_release_date\": [\n",
    "                    \"2010-01-01\",\n",
    "                    \"2011-05-01\",\n",
    "                    \"2020-01-01\",\n",
    "                    \"2020-01-02\",\n",
    "                    \"2019-01-01\",\n",
    "                ],\n",
    "                \"track_artist\": [\"Artist1\", \"Artist1\", \"Artist2\", \"Artist3\", \"Artist2\"],\n",
    "                \"track_id\": [1, 2, 3, 4, 5],\n",
    "            }\n",
    "        )\n",
    "        self.transformer = TopArtistTransformer(num_top_artists=2)\n",
    "\n",
    "    def test_fit(self):\n",
    "        # Test the fitting process\n",
    "        self.transformer.fit(self.data)\n",
    "        self.assertEqual(len(self.transformer.top_artists), 2)\n",
    "        self.assertIn(\"Artist2\", self.transformer.top_artists)\n",
    "        self.assertIn(\"Artist1\", self.transformer.top_artists)\n",
    "\n",
    "    def test_transform(self):\n",
    "        # Fit and then transform the data\n",
    "        self.transformer.fit(self.data)\n",
    "        transformed = self.transformer.transform(self.data)\n",
    "        expected = pd.DataFrame({\"is_top_artist\": [True, True, True, False, True]})\n",
    "        pd.testing.assert_frame_equal(transformed, expected)\n",
    "\n",
    "    def test_feature_names_out(self):\n",
    "        # Check the output feature names\n",
    "        output_names = self.transformer.get_feature_names_out()\n",
    "        self.assertEqual(output_names, [\"is_top_artist\"])\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTopArtistTransformer)\n",
    "unittest.TextTestRunner().run(suite)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Causal Infernece Pipeline\n",
    "\n",
    "\n",
    "def remove_duplicate_tracks(df):\n",
    "    return (\n",
    "        df.sort_values(\"track_popularity\", ascending=False)\n",
    "        .drop_duplicates(\"track_name\")\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_positive_popularity(df):\n",
    "    return df[df[\"track_popularity\"] > 0]\n",
    "\n",
    "\n",
    "def convert_duration_to_mins(df):\n",
    "    df[\"duration_mins\"] = df[\"duration_ms\"] / 60000\n",
    "    df[\"duration_mins\"] = df[\"duration_mins\"].round(2)\n",
    "    return df.drop(columns=[\"duration_ms\"])\n",
    "\n",
    "\n",
    "def extract_release_year(df):\n",
    "    df[\"track_album_release_date\"] = pd.to_datetime(\n",
    "        df[\"track_album_release_date\"], errors=\"coerce\"\n",
    "    )\n",
    "    df[\"release_year\"] = df[\"track_album_release_date\"].dt.year\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_unwanted_columns(df):\n",
    "    return df.drop(\n",
    "        columns=[\n",
    "            \"track_id\",\n",
    "            \"track_name\",\n",
    "            \"track_album_id\",\n",
    "            \"track_album_name\",\n",
    "            \"track_album_release_date\",\n",
    "            \"playlist_name\",\n",
    "            \"playlist_id\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "causal_inference_pipeline = make_pipeline(\n",
    "    FunctionTransformer(remove_duplicate_tracks, validate=False),\n",
    "    FunctionTransformer(filter_positive_popularity, validate=False),\n",
    "    FunctionTransformer(convert_duration_to_mins, validate=False),\n",
    "    FunctionTransformer(extract_release_year, validate=False),\n",
    "    FunctionTransformer(drop_unwanted_columns, validate=False),\n",
    ")\n",
    "\n",
    "with open(\"./src/features/causal_inference_pipeline.pkl\", \"wb\") as file:\n",
    "    pickle.dump(causal_inference_pipeline, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
